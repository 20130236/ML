{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/20130236/ML/blob/main/Lab_8_mssv_HoTen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This lab deals with **GridSearchCV** for tuning the hyper-parameters of an estimator and applying vectorization techniques to the **movie reviews dataset** for classification task. \n",
        "\n",
        "*   **Deadline: 23:59, 17/4/2023**\n",
        "\n"
      ],
      "metadata": {
        "id": "LMzehe0sy5wr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DoVWQ8AEyc-C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be7ad8c4-867f-4e40-fd43-44190955ba74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive/Ml\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn import svm\n",
        "from google.colab import data_table\n",
        "from vega_datasets import data\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score \n",
        "from sklearn.metrics import recall_score  \n",
        "from sklearn.metrics import f1_score \n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics._plot.precision_recall_curve import precision_recall_curve\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from IPython.display import display, HTML\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "drive.mount('/content/gdrive')\n",
        "%cd '/content/gdrive/MyDrive/Ml'\n",
        "data_table.enable_dataframe_formatter()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 1. With **iris** dataset\n",
        "*  1.1. Apply **GridSearchCV** for **SVM** to find the best hyperparameters using the following param_grid.\n",
        "\n",
        "```\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['rbf','linear']}\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "x_dG9SA5OhGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = datasets.load_iris()\n",
        "x = data.data\n",
        "y = data.target"
      ],
      "metadata": {
        "id": "Y7amXK3I6m2y"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid1 = {'C': [0.1, 1, 10, 100, 1000],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['rbf','linear']}\n",
        "# SVM \n",
        "SVM =  svm.SVC(kernel='linear');\n",
        "clf = GridSearchCV(estimator=SVM,param_grid=param_grid1,refit=True,cv=10,n_jobs=4,scoring='accuracy',)\n",
        "clf.fit(x,y)\n",
        "y_predict_svm = clf.predict(x)\n",
        "accuracy_svm = accuracy_score(y, y_predict_svm)\n",
        "precision_svm = precision_score(y, y_predict_svm,average='micro')\n",
        "recall_svm = recall_score(y, y_predict_svm,average='micro')\n",
        "f1_svm = f1_score(y, y_predict_svm,average='micro')\n",
        "\n",
        "svm = {'Accuracy:' : round(accuracy_svm,2), 'Precision:' : round(precision_svm,2), 'Recall:' : round(recall_svm,2), 'F1 score:' : round(f1_svm,2)}\n",
        "svm1 = pd.Series(svm)\n",
        "svm1"
      ],
      "metadata": {
        "id": "62jExOZ952fF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ee21a58-1a81-4d01-ceee-42f4071e6489"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Accuracy:     0.98\n",
              "Precision:    0.98\n",
              "Recall:       0.98\n",
              "F1 score:     0.98\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  1.2. Apply **GridSearchCV** for **kNN** to find the best hyperparameters using the following param_grid.\n",
        "\n",
        "```\n",
        "grid_params = { 'n_neighbors' : [5,7,9,11,13,15],\n",
        "               'weights' : ['uniform','distance'],\n",
        "               'metric' : ['minkowski','euclidean','manhattan']}\n",
        "```\n",
        "where\n",
        "\n",
        "    *  **n_neighbors**: Decide the best k based on the values we have computed earlier.\n",
        "    *  **weights**: Check whether adding weights to the data points is beneficial to the model or not. 'uniform' assigns no weight, while 'distance' weighs points by the inverse of their distances meaning nearer points will have more weight than the farther points.\n",
        "    *  **metric**: The distance metric to be used will calculating the similarity.\n"
      ],
      "metadata": {
        "id": "2g--8cng53sY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grid_params = { 'n_neighbors' : [5,7,9,11,13,15],\n",
        "               'weights' : ['uniform','distance'],\n",
        "               'metric' : ['minkowski','euclidean','manhattan']}\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "clf = GridSearchCV(estimator=knn,param_grid=grid_params,refit=True,cv=10,n_jobs=4,scoring='accuracy')\n",
        "clf.fit(x,y)\n",
        "y_predict_knn = clf.predict(x)\n",
        "accuracy_knn = accuracy_score(y, y_predict_knn)\n",
        "precision_knn = precision_score(y, y_predict_knn,average='micro')\n",
        "recall_knn = recall_score(y, y_predict_knn,average='micro')\n",
        "f1_knn = f1_score(y, y_predict_knn,average='micro')\n",
        "\n",
        "knn = {'Accuracy:' : round(accuracy_knn,2), 'Precision:' : round(precision_knn,2), 'Recall:' : round(recall_knn,2), 'F1 score:' : round(f1_knn,2)}\n",
        "knn1 = pd.Series(knn)\n",
        "knn1"
      ],
      "metadata": {
        "id": "fX0_kItYPism",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddace2db-5dd6-4ae5-a36a-da2c5037403e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Accuracy:     0.98\n",
              "Precision:    0.98\n",
              "Recall:       0.98\n",
              "F1 score:     0.98\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  1.3. Apply **GridSearchCV** for **Random Forest** to find the best hyperparameters using the following param_grid.\n",
        "\n",
        "```\n",
        "param_grid = {\n",
        "    'n_estimators': [25, 50, 100, 150],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'max_depth': [3, 6, 9],\n",
        "    'max_leaf_nodes': [3, 6, 9],\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "3lQSOcjL_TIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [25, 50, 100, 150],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'max_depth': [3, 6, 9],\n",
        "    'max_leaf_nodes': [3, 6, 9],\n",
        "}\n",
        "\n",
        "RFS = RandomForestClassifier(n_estimators=100)\n",
        "clf = GridSearchCV(estimator=RFS,param_grid=param_grid ,refit=True,cv=10,n_jobs=4,scoring='accuracy',)\n",
        "clf.fit(x,y)\n",
        "y_predict_rf = clf.predict(x)\n",
        "accuracy_rf = accuracy_score(y, y_predict_rf)\n",
        "precision_rf = precision_score(y, y_predict_rf,average='micro')\n",
        "recall_rf = recall_score(y, y_predict_rf,average='micro')\n",
        "f1_rf = f1_score(y, y_predict_rf,average='micro')\n",
        "\n",
        "rf = {'Accuracy:' : round(accuracy_rf,2), 'Precision:' : round(precision_rf,2), 'Recall:' : round(recall_rf,2), 'F1 score:' : round(f1_rf,2)}\n",
        "rf1 = pd.Series(rf)\n",
        "rf1"
      ],
      "metadata": {
        "id": "OlyF9WpN_01p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8c985aa-c840-45e7-f9b1-c6b7cea7648f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Accuracy:     0.97\n",
              "Precision:    0.97\n",
              "Recall:       0.97\n",
              "F1 score:     0.97\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   1.4 Compare the best obtained results from 1.1 to 1.3 (use PrettyTable to dispaly the results)"
      ],
      "metadata": {
        "id": "G3N7TD7s_3Kp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({'svm' : svm1 , 'knn' : knn1, 'rf' : rf1 })\n",
        "df"
      ],
      "metadata": {
        "id": "4vV26bEwFO4R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "0c9eb11d-89fc-40e5-d4fb-8353114882a5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             svm   knn    rf\n",
              "Accuracy:   0.98  0.98  0.97\n",
              "Precision:  0.98  0.98  0.97\n",
              "Recall:     0.98  0.98  0.97\n",
              "F1 score:   0.98  0.98  0.97"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b97675bd-a732-43b2-9556-f20035966f16\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>svm</th>\n",
              "      <th>knn</th>\n",
              "      <th>rf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Accuracy:</th>\n",
              "      <td>0.98</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Precision:</th>\n",
              "      <td>0.98</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Recall:</th>\n",
              "      <td>0.98</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F1 score:</th>\n",
              "      <td>0.98</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.97</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b97675bd-a732-43b2-9556-f20035966f16')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b97675bd-a732-43b2-9556-f20035966f16 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b97675bd-a732-43b2-9556-f20035966f16');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 2. \n",
        "For breast cancer dataset (https://tinyurl.com/3vme8hr3) which could be loaded from datasets in sklearn as follows:\n",
        "\n",
        "```\n",
        "#Import scikit-learn dataset library\n",
        "from sklearn import datasets\n",
        "\n",
        "#Load dataset\n",
        "cancer = datasets.load_breast_cancer()\n",
        "```\n",
        "\n",
        "*   Apply **GridSearchCV** to different classification algorithms such as **SVM, kNN, LogisticRegression, RandomForest**.\n",
        "*   Compare the results obtained by the best hyperparameters among classification algorithms."
      ],
      "metadata": {
        "id": "kNv07ARGzOUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = datasets.load_breast_cancer()\n",
        "x = data.data[: 100]\n",
        "y = data.target[: 100]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "nS8wDqT65JsA"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   2.1. Apply **GridSearchCV** to **SVM** \n"
      ],
      "metadata": {
        "id": "pnoVB8J4vV36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid1 = {'C': [0.1, 1, 10, 100, 1000],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['rbf','linear']}\n",
        "# SVM \n",
        "SVM =  svm.SVC(kernel='linear');\n",
        "clf = GridSearchCV(estimator=SVM,param_grid=param_grid1,refit=True,cv=10,n_jobs=4)\n",
        "clf.fit(x_train,y_train)\n",
        "clf.best_params_, clf.best_score_, clf.score(x_test, y_test)\n",
        "\n",
        "svm = {'best hyperparameters' : clf.best_params_}\n",
        "svm1 = pd.Series(svm)\n",
        "svm1"
      ],
      "metadata": {
        "id": "-ZTSvsJdvYqI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acfd2531-7e8f-45c9-edff-523f267460da"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "best hyperparameters    {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   2.2. Apply **GridSearchCV** to **kNN** "
      ],
      "metadata": {
        "id": "ol1U_T_NvcqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grid_params = { 'n_neighbors' : [5,7,9,11,13,15],\n",
        "               'weights' : ['uniform','distance'],\n",
        "               'metric' : ['minkowski','euclidean','manhattan']}\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "clf = GridSearchCV(estimator=knn,param_grid=grid_params,refit=True,cv=10,n_jobs=4,scoring='accuracy')\n",
        "clf.fit(x_train,y_train)\n",
        "\n",
        "knn = {'best hyperparameters' :clf.best_params_}\n",
        "knn1 = pd.Series(knn)\n",
        "knn1"
      ],
      "metadata": {
        "id": "kt71yrAoBwYE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28bd031a-b941-44a3-bc81-e57237187311"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "best hyperparameters    {'metric': 'minkowski', 'n_neighbors': 9, 'wei...\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   2.3. Apply **GridSearchCV** to **LogisticRegression** "
      ],
      "metadata": {
        "id": "pPkAvse-BxNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_params = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
        "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
        "}\n",
        "\n",
        "Lr = LogisticRegression()\n",
        "clf = GridSearchCV(estimator=Lr,param_grid=lr_params ,refit=True,cv=10,n_jobs=4,scoring='accuracy',)\n",
        "clf.fit(x_train,y_train)\n",
        "\n",
        "lr = {'best hyperparameters' : clf.best_params_}\n",
        "lr1 = pd.Series(lr)\n",
        "lr1"
      ],
      "metadata": {
        "id": "nyYjpHFbB1Ci",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d421aa8a-86b8-47ba-821a-feae98fc1d63"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "360 fits failed out of a total of 800.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "40 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "40 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "40 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "40 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "40 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "40 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 64, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "40 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "40 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
            "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 1085, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 521, in _logistic_regression_path\n",
            "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
            "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "40 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py\", line 71, in _check_solver\n",
            "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
            "ValueError: penalty='none' is not supported for the liblinear solver\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [   nan    nan 0.9       nan 0.825  0.9375 0.925  0.9125 0.85   0.825\n",
            "    nan    nan    nan    nan    nan 0.875  0.8875    nan 0.85   0.825\n",
            "    nan    nan 0.9       nan 0.825  0.9375 0.9125 0.9125 0.85   0.825\n",
            "    nan    nan    nan    nan    nan 0.875  0.8875    nan 0.85   0.825\n",
            "    nan    nan 0.9       nan 0.825  0.9375 0.8875 0.925  0.85   0.825\n",
            "    nan    nan    nan    nan    nan 0.875  0.8875    nan 0.85   0.825\n",
            "    nan    nan 0.9125    nan 0.825  0.925  0.8875 0.9125 0.85   0.825\n",
            "    nan    nan    nan    nan    nan 0.875  0.8875    nan 0.85   0.825 ]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "best hyperparameters    {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-...\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   2.4. Apply **GridSearchCV** to **RandomForest** "
      ],
      "metadata": {
        "id": "3NjSLo5jB1xY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [25, 50, 100, 150],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'max_depth': [3, 6, 9],\n",
        "    'max_leaf_nodes': [3, 6, 9],\n",
        "}\n",
        "\n",
        "RFS = RandomForestClassifier(n_estimators=100)\n",
        "clf = GridSearchCV(estimator=RFS,param_grid=param_grid ,refit=True,cv=10,n_jobs=4,scoring='accuracy',)\n",
        "clf.fit(x_train,y_train)\n",
        "\n",
        "rf = {'best hyperparameters' : clf.best_params_}\n",
        "rf1 = pd.Series(rf)\n",
        "rf1"
      ],
      "metadata": {
        "id": "nktGtM0PB7XB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25316f6c-bd7f-4795-ab47-bf8e99fce7b9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "best hyperparameters    {'max_depth': 6, 'max_features': 'sqrt', 'max_...\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   2.5. Compare the best obtained results among classification algorithms (use PrettyTable to dispaly the results) "
      ],
      "metadata": {
        "id": "NZJ3BSHpB9Dx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({'svm' : svm1 , 'knn' : knn1, 'rf' : rf1 ,'lr' : lr1})\n",
        "df"
      ],
      "metadata": {
        "id": "8LS_IYfNCFEj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "9d353d2c-fdfa-405d-e186-79de830b00f9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                              svm  \\\n",
              "best hyperparameters  {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}   \n",
              "\n",
              "                                                                    knn  \\\n",
              "best hyperparameters  {'metric': 'minkowski', 'n_neighbors': 9, 'wei...   \n",
              "\n",
              "                                                                     rf  \\\n",
              "best hyperparameters  {'max_depth': 6, 'max_features': 'sqrt', 'max_...   \n",
              "\n",
              "                                                                     lr  \n",
              "best hyperparameters  {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-83423eaa-ba2d-4aa2-a984-77b8b77e9950\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>svm</th>\n",
              "      <th>knn</th>\n",
              "      <th>rf</th>\n",
              "      <th>lr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>best hyperparameters</th>\n",
              "      <td>{'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}</td>\n",
              "      <td>{'metric': 'minkowski', 'n_neighbors': 9, 'wei...</td>\n",
              "      <td>{'max_depth': 6, 'max_features': 'sqrt', 'max_...</td>\n",
              "      <td>{'C': 0.1, 'penalty': 'l2', 'solver': 'newton-...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83423eaa-ba2d-4aa2-a984-77b8b77e9950')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-83423eaa-ba2d-4aa2-a984-77b8b77e9950 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-83423eaa-ba2d-4aa2-a984-77b8b77e9950');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/99dac6621f6ae8c4/data_table.js\";\n\n      window.createDataTable({\n        data: [[\"best hyperparameters\",\n\"{'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\",\n\"{'metric': 'minkowski', 'n_neighbors': 9, 'weights': 'uniform'}\",\n\"{'max_depth': 6, 'max_features': 'sqrt', 'max_leaf_nodes': 9, 'n_estimators': 25}\",\n\"{'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\"]],\n        columns: [[\"string\", \"index\"], [\"string\", \"svm\"], [\"string\", \"knn\"], [\"string\", \"rf\"], [\"string\", \"lr\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n    "
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 3. \n",
        "The dataset consists of **2000 user-created movie reviews** archived on the IMDb(Internet Movie Database). The reviews are equally partitioned into a positive set and a negative set (1000+1000). Each review consists of a plain text file (.txt) and a class label representing the overall user opinion. \n",
        "The class attribute has only two values: **pos** (positive) or **neg** (negative).\n"
      ],
      "metadata": {
        "id": "b52OPWPD2afi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.1 Importing additional libraries"
      ],
      "metadata": {
        "id": "lDcxOQRmDz_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk, random\n",
        "nltk.download('movie_reviews')#download movie reviews dataset\n",
        "from nltk.corpus import movie_reviews\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "ZjyW06skDwvL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "070711fd-a363-4bd9-8889-4d826f122290"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.2. Movie reviews information"
      ],
      "metadata": {
        "id": "RJpsTIiyv-1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "print(len(movie_reviews.fileids()))\n",
        "print(movie_reviews.categories())\n",
        "print(movie_reviews.words()[:100])\n",
        "print(movie_reviews.fileids()[:10])"
      ],
      "metadata": {
        "id": "5ZE7A0Au1Pg0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7747a291-ae3a-42cb-c387-dfef43df45f6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2000\n",
            "['neg', 'pos']\n",
            "['plot', ':', 'two', 'teen', 'couples', 'go', 'to', ...]\n",
            "['neg/cv000_29416.txt', 'neg/cv001_19502.txt', 'neg/cv002_17424.txt', 'neg/cv003_12683.txt', 'neg/cv004_12641.txt', 'neg/cv005_29357.txt', 'neg/cv006_17022.txt', 'neg/cv007_4992.txt', 'neg/cv008_29326.txt', 'neg/cv009_29417.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.3. Create dataset from movie reviews"
      ],
      "metadata": {
        "id": "6pHmMpqMHS23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [(list(movie_reviews.words(fileid)), category)\n",
        "             for category in movie_reviews.categories()\n",
        "             for fileid in movie_reviews.fileids(category)]\n",
        "random.seed(123)\n",
        "random.shuffle(documents)"
      ],
      "metadata": {
        "id": "45aY6woMHSH5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of Reviews/Documents: {}'.format(len(documents)))\n",
        "print('Corpus Size (words): {}'.format(np.sum([len(d) for (d,l) in documents])))\n",
        "print('Sample Text of Doc 1:')\n",
        "print('-'*30)\n",
        "print(' '.join(documents[0][0][:50])) # first 50 words of the first document"
      ],
      "metadata": {
        "id": "NNke0Da5HqFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "091d3b3d-2df5-4393-ccc3-aadb0f635727"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Reviews/Documents: 2000\n",
            "Corpus Size (words): 1583820\n",
            "Sample Text of Doc 1:\n",
            "------------------------------\n",
            "most movies seem to release a third movie just so it can be called a trilogy . rocky iii seems to kind of fit in that category , but manages to be slightly unique . the rocky formula of \" rocky loses fight / rocky trains / rocky wins fight\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_distr = Counter([label for (words, label) in documents])\n",
        "print(sentiment_distr)"
      ],
      "metadata": {
        "id": "vVFUEhnXHsGd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4aed6154-81d8-4a6a-85cd-c628a6838cfc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'pos': 1000, 'neg': 1000})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.4. Train test split"
      ],
      "metadata": {
        "id": "jTXiEbMzHgVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(documents, test_size = 0.33, random_state=42)"
      ],
      "metadata": {
        "id": "v_-0gZZFHvJN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Sentiment Distrubtion for Train and Test\n",
        "print(Counter([label for (words, label) in train]))\n",
        "print(Counter([label for (words, label) in test]))"
      ],
      "metadata": {
        "id": "UUGlm5TGHvpV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1f520d8-de01-4dcb-f648-74d74294c68e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'neg': 674, 'pos': 666})\n",
            "Counter({'pos': 334, 'neg': 326})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = [' '.join(words) for (words, label) in train]\n",
        "X_test = [' '.join(words) for (words, label) in test]\n",
        "y_train = [label for (words, label) in train]\n",
        "y_test = [label for (words, label) in test]"
      ],
      "metadata": {
        "id": "l1ppl_0RHx1P"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.5. Text Vectorization"
      ],
      "metadata": {
        "id": "7xUaXrjxH6Ee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "tfidf_vec = TfidfVectorizer(min_df = 10, token_pattern = r'[a-zA-Z]+')\n",
        "X_train_bow = tfidf_vec.fit_transform(X_train) # fit train\n",
        "X_test_bow = tfidf_vec.transform(X_test) # transform test"
      ],
      "metadata": {
        "id": "fzwM0nsIH-8l"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.6. Apply **SVM** with **GridSearchCV** "
      ],
      "metadata": {
        "id": "BP1vB3loIF28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid1 = {'C': [0.1, 1, 10, 100, 1000],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['rbf','linear']}\n",
        "# SVM \n",
        "SVM =  svm.SVC(kernel='linear');\n",
        "clf = GridSearchCV(estimator=SVM,param_grid=param_grid1,refit=True,cv=10,n_jobs=4)\n",
        "clf.fit(X_train_bow,y_train)\n",
        "y_predict_svm = clf.predict(X_train_bow)\n",
        "accuracy_svm = accuracy_score(y_train, y_predict_svm)\n",
        "precision_svm = precision_score(y_train, y_predict_svm,average='micro')\n",
        "recall_svm = recall_score(y_train, y_predict_svm,average='micro')\n",
        "f1_svm = f1_score(y_train, y_predict_svm,average='micro')\n",
        "\n",
        "svm = {'Accuracy:' : round(accuracy_svm,2), 'Precision:' : round(precision_svm,2), 'Recall:' : round(recall_svm,2), 'F1 score:' : round(f1_svm,2)}\n",
        "svm1 = pd.Series(svm)\n",
        "svm1"
      ],
      "metadata": {
        "id": "b3FHQqh1Hlrd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e1643cd-9c88-4f0b-febc-a90ca20fa0e8"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Accuracy:     0.99\n",
              "Precision:    0.99\n",
              "Recall:       0.99\n",
              "F1 score:     0.99\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.7. Apply **RandomForest** with **GridSearchCV** "
      ],
      "metadata": {
        "id": "N1Fy8jYBIdxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [25, 50, 100, 150],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'max_depth': [3, 6, 9],\n",
        "    'max_leaf_nodes': [3, 6, 9],\n",
        "}\n",
        "\n",
        "RFS = RandomForestClassifier(n_estimators=100)\n",
        "clf = GridSearchCV(estimator=RFS,param_grid=param_grid ,refit=True,cv=10,n_jobs=4,scoring='accuracy',)\n",
        "clf.fit(X_train_bow,y_train)\n",
        "y_predict_rf = clf.predict(X_train_bow)\n",
        "accuracy_rf = accuracy_score(y_train, y_predict_rf)\n",
        "precision_rf = precision_score(y_train, y_predict_rf,average='micro')\n",
        "recall_rf = recall_score(y_train, y_predict_rf,average='micro')\n",
        "f1_rf = f1_score(y_train, y_predict_rf,average='micro')\n",
        "\n",
        "rf = {'Accuracy:' : round(accuracy_rf,2), 'Precision:' : round(precision_rf,2), 'Recall:' : round(recall_rf,2), 'F1 score:' : round(f1_rf,2)}\n",
        "rf1 = pd.Series(rf)\n",
        "rf1"
      ],
      "metadata": {
        "id": "Fyfw2R-gIhWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.8. Apply **kNN** with **GridSearchCV** "
      ],
      "metadata": {
        "id": "_btsVKjIIiLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grid_params = { 'n_neighbors' : [5,7,9,11,13,15],\n",
        "               'weights' : ['uniform','distance'],\n",
        "               'metric' : ['minkowski','euclidean','manhattan']}\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "clf = GridSearchCV(estimator=knn,param_grid=grid_params,refit=True,cv=10,n_jobs=4,scoring='accuracy')\n",
        "clf.fit(X_train_bow,y_train)\n",
        "y_predict_knn = clf.predict(X_train_bow)\n",
        "accuracy_knn = accuracy_score(y_train, y_predict_knn)\n",
        "precision_knn = precision_score(y_train, y_predict_knn,average='micro')\n",
        "recall_knn = recall_score(y_train, y_predict_knn,average='micro')\n",
        "f1_knn = f1_score(y_train, y_predict_knn,average='micro')\n",
        "\n",
        "knn = {'Accuracy:' : round(accuracy_knn,2), 'Precision:' : round(precision_knn,2), 'Recall:' : round(recall_knn,2), 'F1 score:' : round(f1_knn,2)}\n",
        "knn1 = pd.Series(knn)\n",
        "knn1"
      ],
      "metadata": {
        "id": "IZmFu1ZQImhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.9. Apply **LogisticRegression** with **GridSearchCV** "
      ],
      "metadata": {
        "id": "0Ix_HeVGIvDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_params = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
        "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
        "}\n",
        "\n",
        "Lr = LogisticRegression()\n",
        "clf = GridSearchCV(estimator=Lr,param_grid=lr_params ,refit=True,cv=10,n_jobs=4,scoring='accuracy',)\n",
        "clf.fit(X_train_bow,y_train)\n",
        "y_predict_lr = clf.predict(X_train_bow)\n",
        "accuracy_lr = accuracy_score(y_train, y_predict_lr)\n",
        "precision_lr = precision_score(y_train, y_predict_lr,average='micro')\n",
        "recall_lr = recall_score(y_train, y_predict_lr,average='micro')\n",
        "f1_lr = f1_score(y_train, y_predict_lr,average='micro')\n",
        "\n",
        "lr = {'Accuracy:' : round(accuracy_lr,2), 'Precision:' : round(precision_lr,2), 'Recall:' : round(recall_lr,2), 'F1 score:' : round(f1_lr,2)}\n",
        "lr1 = pd.Series(lr)\n",
        "lr1"
      ],
      "metadata": {
        "id": "sTd3alCMIr-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.10. Compare the best obtained results among classification algorithms (use PrettyTable to dispaly the results) "
      ],
      "metadata": {
        "id": "nhYF2y6eI058"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({'svm' : svm1 , 'knn' : knn1, 'rf' : rf1 , 'lr' : lr1})\n",
        "df"
      ],
      "metadata": {
        "id": "B6yN7QvWCvzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finally,\n",
        "Save a copy in your Github. Remember renaming the notebook."
      ],
      "metadata": {
        "id": "Ok7RGkea_b7n"
      }
    }
  ]
}